{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_NAME = 'block5_conv3'  # VGG16\n",
    "model = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(LAYER_NAME).output, model.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_model.layers[-1].activation = tf.keras.activations.softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cam(img_path, cls_idx=-1, colormap_type=cv2.COLORMAP_JET, show_max_cam=False, img_size=224, softmax=True, omit_neg=True):\n",
    "    img_bgr = cv2.imread(img_path)\n",
    "    if img_bgr is None:\n",
    "        print(\"failed to load image\")\n",
    "        return [None]*5\n",
    "    else:\n",
    "        img_bgr_resize = cv2.resize(img_bgr, (img_size, img_size))\n",
    "        img_rgb = cv2.cvtColor(img_bgr_resize, cv2.COLOR_BGR2RGB)\n",
    "        #img_rgb = cv2.resize(img_rgb, (img_size, img_size))\n",
    "        img_norm = ((img_rgb-127.5)/127.5).astype(np.float32)\n",
    "        \n",
    "    with tf.GradientTape() as tape:\n",
    "        print(img_norm.shape)\n",
    "        conv_outputs, predictions = grad_model(np.array([img_norm]))\n",
    "        print(conv_outputs.shape, predictions.shape)\n",
    "        if cls_idx == -1:\n",
    "            cls_idx = np.argmax(predictions[0]) \n",
    "        preds = predictions[:, cls_idx]\n",
    "\n",
    "    #conv_outputs = model.backbone.id_block5_2.output\n",
    "    output = conv_outputs[0]\n",
    "    grads = tape.gradient(preds, conv_outputs)[0]\n",
    "\n",
    "    weights = tf.reduce_mean(grads, axis=(0, 1))\n",
    "\n",
    "    cam = np.zeros(output.shape[0: 2], dtype = np.float32)\n",
    "\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * output[:, :, i]\n",
    "\n",
    "    if show_max_cam:\n",
    "        print(np.max(cam), np.min(cam))\n",
    "    #print(cam.shape)\n",
    "    \n",
    "    if omit_neg:\n",
    "        cam = np.maximum(cam, 0) / np.max(cam)\n",
    "    else:\n",
    "        cam = (cam.numpy()-np.min(cam)) / (np.max(cam)-np.min(cam))\n",
    "    cam = cv2.resize(cam, (img_size, img_size))\n",
    "\n",
    "    cam = np.uint8(255*cam)\n",
    "    if colormap_type is None:\n",
    "        cam = cv2.cvtColor(cam, cv2.COLOR_GRAY2BGR)\n",
    "    else:\n",
    "        cam = cv2.applyColorMap(cam, colormap_type)\n",
    "    \n",
    "    heatmap = cv2.addWeighted(img_bgr_resize.astype('uint8'), 0.5, cam, 1, 0)\n",
    "    \n",
    "    if softmax:\n",
    "        preds = predictions[0]\n",
    "    else:\n",
    "        preds = tf.nn.softmax(predictions[0])\n",
    "    argmax = np.argmax(preds)\n",
    "    \n",
    "    h, w, c = img_bgr_resize.shape\n",
    "    img_final = np.ones([h, w*2, c])\n",
    "    img_final[0:h, 0:w] = img_bgr_resize\n",
    "    img_final[0:h, w:2*w] = heatmap\n",
    "    img_final = img_final.astype(np.uint8)\n",
    "\n",
    "    return img_bgr, heatmap, img_final, argmax, preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad CAM++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cam_pp(img_path, cls_idx=-1, colormap_type=cv2.COLORMAP_JET, show_max_cam=False, img_size=224, softmax=True, omit_neg=True):\n",
    "    img_bgr = cv2.imread(img_path)\n",
    "    if img_bgr is None:\n",
    "        print(\"failed to load image\")\n",
    "        return [None]*5\n",
    "    else:\n",
    "        img_bgr_resize = cv2.resize(img_bgr, (img_size, img_size))\n",
    "        img_rgb = cv2.cvtColor(img_bgr_resize, cv2.COLOR_BGR2RGB)\n",
    "        #img_rgb = cv2.resize(img_rgb, (img_size, img_size))\n",
    "        img_norm = ((img_rgb-127.5)/127.5).astype(np.float32)\n",
    "        #img_norm = (img_rgb/255).astype(np.float32)\n",
    "        \n",
    "        #img_bgr_resize = cv2.resize(img_bgr, (img_size, img_size))\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(np.array([img_norm]))\n",
    "#         if softmax:\n",
    "#             predictions = tf.nn.softmax(predictions)\n",
    "        if cls_idx == -1:\n",
    "            cls_idx = np.argmax(predictions[0]) \n",
    "        preds = predictions[:, cls_idx]\n",
    "\n",
    "    #conv_outputs = model.backbone.id_block5_2.output\n",
    "    conv_output = conv_outputs[0]\n",
    "    grads = tape.gradient(preds, conv_outputs)[0]\n",
    "\n",
    "    score = tf.exp(preds)\n",
    "    \n",
    "    first_derivative = score * grads\n",
    "    second_derivative = first_derivative * grads\n",
    "    third_derivative = second_derivative * grads\n",
    "\n",
    "    \n",
    "    global_sum = np.sum(tf.reshape(conv_output, (-1, conv_output.shape[2])), axis=0)  # [2048]\n",
    " \n",
    "    alpha_denom = second_derivative*2 + third_derivative * tf.reshape(global_sum, (1, 1, conv_output.shape[2])) + 1e-5\n",
    "    \n",
    "    alphas = conv_output / alpha_denom  # [10, 10, 2048]\n",
    "    \n",
    "    weights = np.maximum(first_derivative, 0)\n",
    "    \n",
    "    ## normalize the alphas for each feature map\n",
    "    alphas_thresh = np.where(weights, alphas, 0)  # threhold the alphas by weights\n",
    "    alphas_sum = np.sum(alphas_thresh, axis=(0, 1))  # sum the alphas over the feature map, [2048]\n",
    "    alphas_norm = np.where(alphas_sum!=0, alphas_sum, np.ones(alphas_sum.shape))  \n",
    "    \n",
    "    alphas /= alphas_norm\n",
    "\n",
    "    \n",
    "    weights = np.maximum(first_derivative, 0) * alphas\n",
    "    \n",
    "    weights = np.sum(weights, axis=(0, 1))  # [2048]\n",
    "    #print(weights, 'aaa')\n",
    "    cam = np.zeros(conv_output.shape[0: 2], dtype = np.float32)\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * conv_output[:, :, i]\n",
    "    \n",
    "    \n",
    "    if show_max_cam:\n",
    "        print(np.max(cam), np.min(cam))\n",
    "    #print(cam.shape)\n",
    "    \n",
    "    if omit_neg:\n",
    "        cam = np.maximum(cam, 0) / np.max(cam)\n",
    "    else:\n",
    "        cam = (cam.numpy()-np.min(cam)) / (np.max(cam)-np.min(cam))\n",
    "    cam = cv2.resize(cam, (img_size, img_size))\n",
    "\n",
    "    cam = np.uint8(255*cam)\n",
    "    if colormap_type is None:\n",
    "        cam = cv2.cvtColor(cam, cv2.COLOR_GRAY2BGR)\n",
    "    else:\n",
    "        cam = cv2.applyColorMap(cam, colormap_type)\n",
    "    \n",
    "    heatmap = cv2.addWeighted(img_bgr_resize.astype('uint8'), 0.5, cam, 1, 0)\n",
    "    \n",
    "    if softmax:\n",
    "        preds = predictions[0]\n",
    "    else:\n",
    "        preds = tf.nn.softmax(predictions[0])\n",
    "    argmax = np.argmax(preds)\n",
    "    \n",
    "    h, w, c = img_bgr_resize.shape\n",
    "    img_final = np.ones([h, w*2, c])\n",
    "    img_final[0:h, 0:w] = img_bgr_resize\n",
    "    img_final[0:h, w:2*w] = heatmap\n",
    "    img_final = img_final.astype(np.uint8)\n",
    "\n",
    "    return img_bgr, heatmap, img_final, argmax, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_path = \"cat.jpg\"\n",
    "img_path = \"bear.jpg\"\n",
    "#img_path = \"elephant.jpg\"\n",
    "#img_path = \"goldfish.jpg\"\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, figsize=(10, 7), sharex=True, gridspec_kw={'hspace': 0.05})\n",
    "\n",
    "#grad_cam_pp = grad_cam\n",
    "cls_idx = -1\n",
    "src_img, heatmap, img_final, argmax, scores = grad_cam(img_path, cls_idx, cv2.COLORMAP_JET, show_max_cam=True, img_size=224, omit_neg=True)\n",
    "src_img2, heatmap2, img_final2, argmax2, scores2 = grad_cam_pp(img_path, cls_idx, cv2.COLORMAP_JET, show_max_cam=True, img_size=224, omit_neg=True)\n",
    "img_final = cv2.cvtColor(img_final, cv2.COLOR_BGR2RGB)\n",
    "img_final2 = cv2.cvtColor(img_final2, cv2.COLOR_BGR2RGB)\n",
    "print(argmax)\n",
    "#plt.imshow(img_final)\n",
    "ax[0].imshow(img_final)\n",
    "ax[1].imshow(img_final2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
