{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_NAME = 'block5_conv3'  # VGG16\n",
    "model = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(LAYER_NAME).output, model.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(img_path):\n",
    "    assert os.path.isfile(img_path)\n",
    "    img_bgr = cv2.resize(cv2.imread(img_path), (224, 224))\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    img_norm = preprocess_input(np.asarray([np.array(img_rgb)]))\n",
    "    \n",
    "    return img_rgb, img_bgr, img_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grads(img_norm, cls_idx=-1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_norm)\n",
    "        if cls_idx == -1:\n",
    "            cls_idx = np.argmax(predictions[0]) \n",
    "        preds = predictions[:, cls_idx]\n",
    "\n",
    "    conv_output = conv_outputs[0]\n",
    "    grads = tape.gradient(preds, conv_outputs)[0]\n",
    "    \n",
    "    argmax = np.argmax(predictions[0])\n",
    "\n",
    "    print(argmax, decode_predictions(predictions.numpy())[0][0])\n",
    "    \n",
    "    return grads, conv_output, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_heatmap(img_bgr, cam, colormap=cv2.COLORMAP_JET, omit_neg=True):\n",
    "    if omit_neg:\n",
    "        cam = np.maximum(cam, 0) / np.max(cam)\n",
    "    else:\n",
    "        cam = (cam.numpy()-np.min(cam)) / (np.max(cam)-np.min(cam))\n",
    "    cam = cv2.resize(cam, (img_bgr.shape[0], img_bgr.shape[1]))\n",
    "\n",
    "    cam = np.uint8(255*cam)\n",
    "    if colormap is None:\n",
    "        cam = cv2.cvtColor(cam, cv2.COLOR_GRAY2BGR)\n",
    "    else:\n",
    "        cam = cv2.applyColorMap(cam, colormap)\n",
    "    \n",
    "    heatmap = cv2.addWeighted(img_bgr.astype('uint8'), 0.5, cam, 1, 0)\n",
    "    \n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad CAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For details on Grad-CAM, see the paper:\n",
    "###   [Grad-CAM: Why did you say that? Visual Explanations from Deep Networks via Gradient-based Localization](https://arxiv.org/pdf/1610.02391v1.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cam(grads, conv_output):\n",
    "    weights = tf.reduce_mean(grads, axis=(0, 1))\n",
    "\n",
    "    cam = np.zeros(conv_output.shape[0: 2], dtype = np.float32)\n",
    "\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * conv_output[:, :, i]\n",
    "    \n",
    "    return cam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad CAM++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For details on GradCAM++, see the paper:\n",
    "###     [GradCAM++: Improved Visual Explanations for Deep Convolutional Networks](https://arxiv.org/pdf/1710.11063.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cam_pp(grads, conv_output, preds):\n",
    "    score = tf.exp(preds)\n",
    "    \n",
    "    first_derivative = score * grads\n",
    "    second_derivative = first_derivative * grads\n",
    "    third_derivative = second_derivative * grads\n",
    "\n",
    "    \n",
    "    global_sum = np.sum(tf.reshape(conv_output, (-1, conv_output.shape[2])), axis=0)  # [2048]\n",
    " \n",
    "    alpha_denom = second_derivative*2 + third_derivative * tf.reshape(global_sum, (1, 1, conv_output.shape[2])) + 1e-5\n",
    "    \n",
    "    alphas = conv_output / alpha_denom  # [10, 10, 2048]\n",
    "    \n",
    "    weights = np.maximum(first_derivative, 0)\n",
    "    \n",
    "    ## normalize the alphas for each feature map\n",
    "    alphas_thresh = np.where(weights, alphas, 0)  # threhold the alphas by weights\n",
    "    alphas_sum = np.sum(alphas_thresh, axis=(0, 1))  # sum the alphas over the feature map, [2048]\n",
    "    alphas_norm = np.where(alphas_sum!=0, alphas_sum, np.ones(alphas_sum.shape))  \n",
    "    \n",
    "    alphas /= alphas_norm\n",
    "    \n",
    "    weights = np.maximum(first_derivative, 0) * alphas\n",
    "    \n",
    "    weights = np.sum(weights, axis=(0, 1))  # [2048]\n",
    "    cam = np.zeros(conv_output.shape[0: 2], dtype = np.float32)\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * conv_output[:, :, i]\n",
    "    \n",
    "    return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_heatmap(img_path, cls_idx=-1, colormap=cv2.COLORMAP_JET, omit_neg=True):\n",
    "    img_rgb, img_bgr, img_norm = get_img(img_path)\n",
    "    \n",
    "    grads, conv_output, preds = get_grads(img_norm, cls_idx=-1)\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=3, figsize=(10, 7), subplot_kw= {'xticks': [], 'yticks': []} )\n",
    "\n",
    "    ax[0].set_title(\"Original Image\")\n",
    "    ax[0].imshow(img_rgb)\n",
    "    \n",
    "    cam = grad_cam(grads, conv_output)\n",
    "    heatmap = synthesize_heatmap(img_bgr, cam, colormap, omit_neg)\n",
    "    ax[1].set_title(\"Grad CAM\")\n",
    "    ax[1].imshow(heatmap)\n",
    "    \n",
    "    cam = grad_cam_pp(grads, conv_output, preds)\n",
    "    heatmap = synthesize_heatmap(img_bgr, cam, colormap, omit_neg)\n",
    "    ax[2].set_title(\"Grad CAM++\")\n",
    "    ax[2].imshow(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_heatmap(\"bear.jpg\", colormap=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_heatmap(\"bear.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_heatmap(\"cat.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_heatmap(\"cat2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_heatmap(\"elephant.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_heatmap(\"goldfish.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
